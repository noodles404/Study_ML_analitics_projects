{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lzk7iX_CodX6",
    "tags": []
   },
   "source": [
    "# <img align=\"left\" src=\"./images/movie_camera.png\"     style=\" width:40px;  \" > Practice lab: Collaborative Filtering Recommender Systems\n",
    "\n",
    "In this exercise, you will implement collaborative filtering to build a recommender system for movies. \n",
    "\n",
    "# <img align=\"left\" src=\"./images/film_reel.png\"     style=\" width:40px;  \" > Outline\n",
    "- [ 1 - Notation](#1)\n",
    "- [ 2 - Recommender Systems](#2)\n",
    "- [ 3 - Movie ratings dataset](#3)\n",
    "- [ 4 - Collaborative filtering learning algorithm](#4)\n",
    "  - [ 4.1 Collaborative filtering cost function](#4.1)\n",
    "    - [ Exercise 1](#ex01)\n",
    "- [ 5 - Learning movie recommendations](#5)\n",
    "- [ 6 - Recommendations](#6)\n",
    "- [ 7 - Congratulations!](#7)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**NOTE:** To prevent errors from the autograder, you are not allowed to edit or delete non-graded cells in this lab. Please also refrain from adding any new cells. \n",
    "**Once you have passed this assignment** and want to experiment with any of the non-graded code, you may follow the instructions at the bottom of this notebook._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Packages <img align=\"left\" src=\"./images/film_strip_vertical.png\"     style=\" width:40px;   \" >\n",
    "We will use the now familiar NumPy and Tensorflow Packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\black\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\black\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\black\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\black\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\black\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\black\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.75.1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\black\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\black\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\black\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Collecting typing_extensions>=3.6.6 (from tensorflow)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\black\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\black\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\black\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\black\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\black\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\black\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\black\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (10.4.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\black\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\black\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\black\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\black\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\black\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "   ---------------------------------------- 0.0/331.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/331.9 MB 16.7 MB/s eta 0:00:20\n",
      "    --------------------------------------- 6.8/331.9 MB 22.1 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 10.5/331.9 MB 19.2 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 14.2/331.9 MB 18.5 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 17.8/331.9 MB 18.4 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 21.0/331.9 MB 17.7 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 23.9/331.9 MB 17.0 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 26.0/331.9 MB 16.0 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 27.8/331.9 MB 15.3 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 29.9/331.9 MB 14.7 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 32.0/331.9 MB 14.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 34.3/331.9 MB 13.8 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 36.4/331.9 MB 13.5 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 38.5/331.9 MB 13.2 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 40.6/331.9 MB 13.0 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 42.5/331.9 MB 12.7 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 44.0/331.9 MB 12.4 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 45.6/331.9 MB 12.1 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 47.4/331.9 MB 11.9 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 49.0/331.9 MB 11.7 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 50.3/331.9 MB 11.4 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 51.4/331.9 MB 11.2 MB/s eta 0:00:26\n",
      "   ------ --------------------------------- 52.7/331.9 MB 10.9 MB/s eta 0:00:26\n",
      "   ------ --------------------------------- 53.7/331.9 MB 10.6 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 54.5/331.9 MB 10.4 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 55.6/331.9 MB 10.1 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 56.6/331.9 MB 9.9 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 57.7/331.9 MB 9.7 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 58.7/331.9 MB 9.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 59.5/331.9 MB 9.4 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 60.0/331.9 MB 9.2 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 60.8/331.9 MB 9.0 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 61.6/331.9 MB 8.9 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 62.7/331.9 MB 8.7 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 63.4/331.9 MB 8.5 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 64.2/331.9 MB 8.4 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 65.0/331.9 MB 8.3 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 66.1/331.9 MB 8.2 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 66.8/331.9 MB 8.1 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 67.9/331.9 MB 8.0 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 68.7/331.9 MB 7.9 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 69.7/331.9 MB 7.8 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 70.5/331.9 MB 7.7 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 71.3/331.9 MB 7.7 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 72.1/331.9 MB 7.5 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 72.9/331.9 MB 7.4 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 73.7/331.9 MB 7.4 MB/s eta 0:00:36\n",
      "   -------- ------------------------------- 74.4/331.9 MB 7.3 MB/s eta 0:00:36\n",
      "   --------- ------------------------------ 75.2/331.9 MB 7.2 MB/s eta 0:00:36\n",
      "   --------- ------------------------------ 75.8/331.9 MB 7.1 MB/s eta 0:00:36\n",
      "   --------- ------------------------------ 76.3/331.9 MB 7.1 MB/s eta 0:00:37\n",
      "   --------- ------------------------------ 76.8/331.9 MB 6.9 MB/s eta 0:00:37\n",
      "   --------- ------------------------------ 77.1/331.9 MB 6.9 MB/s eta 0:00:38\n",
      "   --------- ------------------------------ 77.6/331.9 MB 6.7 MB/s eta 0:00:38\n",
      "   --------- ------------------------------ 77.9/331.9 MB 6.7 MB/s eta 0:00:39\n",
      "   --------- ------------------------------ 78.1/331.9 MB 6.6 MB/s eta 0:00:39\n",
      "   --------- ------------------------------ 78.6/331.9 MB 6.5 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 79.2/331.9 MB 6.4 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 79.4/331.9 MB 6.3 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 80.0/331.9 MB 6.3 MB/s eta 0:00:41\n",
      "   --------- ------------------------------ 80.5/331.9 MB 6.2 MB/s eta 0:00:41\n",
      "   --------- ------------------------------ 80.7/331.9 MB 6.2 MB/s eta 0:00:41\n",
      "   --------- ------------------------------ 81.3/331.9 MB 6.1 MB/s eta 0:00:42\n",
      "   --------- ------------------------------ 81.5/331.9 MB 6.0 MB/s eta 0:00:42\n",
      "   --------- ------------------------------ 82.1/331.9 MB 5.9 MB/s eta 0:00:43\n",
      "   --------- ------------------------------ 82.6/331.9 MB 5.9 MB/s eta 0:00:43\n",
      "   --------- ------------------------------ 82.8/331.9 MB 5.8 MB/s eta 0:00:43\n",
      "   ---------- ----------------------------- 83.4/331.9 MB 5.7 MB/s eta 0:00:44\n",
      "   ---------- ----------------------------- 83.9/331.9 MB 5.7 MB/s eta 0:00:44\n",
      "   ---------- ----------------------------- 84.4/331.9 MB 5.6 MB/s eta 0:00:44\n",
      "   ---------- ----------------------------- 84.7/331.9 MB 5.6 MB/s eta 0:00:45\n",
      "   ---------- ----------------------------- 85.2/331.9 MB 5.6 MB/s eta 0:00:45\n",
      "   ---------- ----------------------------- 85.7/331.9 MB 5.5 MB/s eta 0:00:45\n",
      "   ---------- ----------------------------- 86.5/331.9 MB 5.5 MB/s eta 0:00:45\n",
      "   ---------- ----------------------------- 87.0/331.9 MB 5.4 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 87.6/331.9 MB 5.4 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 88.1/331.9 MB 5.4 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 88.6/331.9 MB 5.3 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 88.9/331.9 MB 5.3 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 89.4/331.9 MB 5.2 MB/s eta 0:00:47\n",
      "   ---------- ----------------------------- 89.9/331.9 MB 5.2 MB/s eta 0:00:47\n",
      "   ---------- ----------------------------- 90.4/331.9 MB 5.2 MB/s eta 0:00:47\n",
      "   ---------- ----------------------------- 91.0/331.9 MB 5.1 MB/s eta 0:00:47\n",
      "   ----------- ---------------------------- 91.8/331.9 MB 5.1 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 92.3/331.9 MB 5.1 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 92.8/331.9 MB 5.1 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 93.6/331.9 MB 5.0 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 94.1/331.9 MB 5.0 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 94.6/331.9 MB 5.0 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 95.4/331.9 MB 5.0 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 96.2/331.9 MB 4.9 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 96.7/331.9 MB 4.9 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 97.5/331.9 MB 4.9 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 98.3/331.9 MB 4.9 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 99.1/331.9 MB 4.9 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 99.9/331.9 MB 4.9 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 100.7/331.9 MB 4.8 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 101.4/331.9 MB 4.8 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 102.2/331.9 MB 4.8 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 103.3/331.9 MB 4.8 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 104.1/331.9 MB 4.8 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 104.9/331.9 MB 4.8 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 105.9/331.9 MB 4.8 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 106.7/331.9 MB 4.8 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 107.7/331.9 MB 4.8 MB/s eta 0:00:47\n",
      "   ------------- -------------------------- 108.8/331.9 MB 4.8 MB/s eta 0:00:47\n",
      "   ------------- -------------------------- 109.8/331.9 MB 4.8 MB/s eta 0:00:47\n",
      "   ------------- -------------------------- 110.6/331.9 MB 4.8 MB/s eta 0:00:47\n",
      "   ------------- -------------------------- 111.7/331.9 MB 4.8 MB/s eta 0:00:47\n",
      "   ------------- -------------------------- 112.7/331.9 MB 4.8 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 113.8/331.9 MB 4.8 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 114.8/331.9 MB 4.8 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 116.1/331.9 MB 4.8 MB/s eta 0:00:46\n",
      "   -------------- ------------------------- 117.2/331.9 MB 4.8 MB/s eta 0:00:45\n",
      "   -------------- ------------------------- 118.2/331.9 MB 4.8 MB/s eta 0:00:45\n",
      "   -------------- ------------------------- 119.3/331.9 MB 4.8 MB/s eta 0:00:45\n",
      "   -------------- ------------------------- 120.6/331.9 MB 4.8 MB/s eta 0:00:44\n",
      "   -------------- ------------------------- 121.6/331.9 MB 4.8 MB/s eta 0:00:44\n",
      "   -------------- ------------------------- 122.9/331.9 MB 4.8 MB/s eta 0:00:44\n",
      "   -------------- ------------------------- 124.3/331.9 MB 4.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 125.6/331.9 MB 4.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 126.6/331.9 MB 4.8 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 127.9/331.9 MB 4.9 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 129.2/331.9 MB 4.9 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 130.5/331.9 MB 4.9 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 131.9/331.9 MB 4.9 MB/s eta 0:00:41\n",
      "   ---------------- ----------------------- 133.4/331.9 MB 4.9 MB/s eta 0:00:41\n",
      "   ---------------- ----------------------- 134.7/331.9 MB 4.9 MB/s eta 0:00:41\n",
      "   ---------------- ----------------------- 136.3/331.9 MB 4.9 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 137.9/331.9 MB 5.0 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 139.7/331.9 MB 5.0 MB/s eta 0:00:39\n",
      "   ----------------- ---------------------- 141.3/331.9 MB 5.0 MB/s eta 0:00:39\n",
      "   ----------------- ---------------------- 143.4/331.9 MB 5.0 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 145.0/331.9 MB 5.0 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 146.3/331.9 MB 5.1 MB/s eta 0:00:37\n",
      "   ----------------- ---------------------- 147.3/331.9 MB 5.0 MB/s eta 0:00:37\n",
      "   ----------------- ---------------------- 148.1/331.9 MB 5.1 MB/s eta 0:00:37\n",
      "   ----------------- ---------------------- 149.2/331.9 MB 5.0 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 149.9/331.9 MB 5.0 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 150.7/331.9 MB 5.0 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 151.5/331.9 MB 5.0 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 152.3/331.9 MB 4.8 MB/s eta 0:00:38\n",
      "   ------------------ --------------------- 153.4/331.9 MB 4.7 MB/s eta 0:00:38\n",
      "   ------------------ --------------------- 154.1/331.9 MB 4.6 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 155.2/331.9 MB 4.5 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 156.0/331.9 MB 4.5 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 157.0/331.9 MB 4.4 MB/s eta 0:00:40\n",
      "   ------------------- -------------------- 157.8/331.9 MB 4.4 MB/s eta 0:00:40\n",
      "   ------------------- -------------------- 158.9/331.9 MB 4.3 MB/s eta 0:00:40\n",
      "   ------------------- -------------------- 159.9/331.9 MB 4.3 MB/s eta 0:00:40\n",
      "   ------------------- -------------------- 161.0/331.9 MB 4.3 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 162.0/331.9 MB 4.2 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 163.1/331.9 MB 4.2 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 164.1/331.9 MB 4.2 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 165.2/331.9 MB 4.1 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 166.2/331.9 MB 4.1 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 167.2/331.9 MB 4.1 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 168.3/331.9 MB 4.1 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 169.6/331.9 MB 4.1 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 170.7/331.9 MB 4.0 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 172.0/331.9 MB 4.0 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 173.3/331.9 MB 4.0 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 174.3/331.9 MB 4.0 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 175.4/331.9 MB 4.0 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 176.4/331.9 MB 4.0 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 176.9/331.9 MB 4.0 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 177.7/331.9 MB 4.0 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 178.3/331.9 MB 4.0 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 179.0/331.9 MB 4.0 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 179.8/331.9 MB 4.0 MB/s eta 0:00:38\n",
      "   --------------------- ------------------ 180.4/331.9 MB 4.0 MB/s eta 0:00:38\n",
      "   --------------------- ------------------ 180.9/331.9 MB 4.0 MB/s eta 0:00:38\n",
      "   --------------------- ------------------ 181.4/331.9 MB 4.0 MB/s eta 0:00:38\n",
      "   --------------------- ------------------ 182.2/331.9 MB 4.0 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 182.7/331.9 MB 4.0 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 183.2/331.9 MB 4.0 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 184.0/331.9 MB 4.0 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 184.5/331.9 MB 3.9 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 185.3/331.9 MB 3.9 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 185.9/331.9 MB 3.9 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 186.6/331.9 MB 3.9 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 187.4/331.9 MB 3.9 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 188.2/331.9 MB 3.9 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 188.7/331.9 MB 3.9 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 189.5/331.9 MB 3.9 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 190.1/331.9 MB 3.9 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 190.6/331.9 MB 3.9 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 191.1/331.9 MB 3.9 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 191.6/331.9 MB 3.9 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 192.2/331.9 MB 3.9 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 192.7/331.9 MB 3.9 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 192.9/331.9 MB 3.9 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 193.2/331.9 MB 3.9 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 193.7/331.9 MB 3.9 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 194.0/331.9 MB 3.9 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 194.5/331.9 MB 3.9 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 195.0/331.9 MB 3.9 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 195.3/331.9 MB 3.9 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 195.8/331.9 MB 3.9 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 196.3/331.9 MB 3.9 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 196.9/331.9 MB 3.9 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 197.4/331.9 MB 3.9 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 197.7/331.9 MB 3.9 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 198.2/331.9 MB 3.9 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 198.4/331.9 MB 3.9 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 199.0/331.9 MB 3.9 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 199.5/331.9 MB 3.9 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 200.0/331.9 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 200.3/331.9 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 200.8/331.9 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 201.3/331.9 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 201.9/331.9 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 202.4/331.9 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 202.9/331.9 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 203.2/331.9 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 203.4/331.9 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 203.7/331.9 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 203.9/331.9 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 203.9/331.9 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 204.2/331.9 MB 3.8 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 204.5/331.9 MB 3.8 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 204.7/331.9 MB 3.8 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 205.0/331.9 MB 3.8 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 205.3/331.9 MB 3.8 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 205.5/331.9 MB 3.8 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 205.8/331.9 MB 3.8 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 206.0/331.9 MB 3.8 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 206.6/331.9 MB 3.7 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 206.8/331.9 MB 3.7 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 206.8/331.9 MB 3.7 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 207.1/331.9 MB 3.7 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 207.4/331.9 MB 3.7 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 207.6/331.9 MB 3.7 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 207.6/331.9 MB 3.7 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 207.9/331.9 MB 3.6 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 208.1/331.9 MB 3.6 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 208.4/331.9 MB 3.6 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 208.7/331.9 MB 3.6 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 208.9/331.9 MB 3.5 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 209.2/331.9 MB 3.5 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 209.5/331.9 MB 3.5 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 209.7/331.9 MB 3.5 MB/s eta 0:00:36\n",
      "   ------------------------- -------------- 210.0/331.9 MB 3.5 MB/s eta 0:00:36\n",
      "   ------------------------- -------------- 210.5/331.9 MB 3.4 MB/s eta 0:00:36\n",
      "   ------------------------- -------------- 210.8/331.9 MB 3.4 MB/s eta 0:00:36\n",
      "   ------------------------- -------------- 211.3/331.9 MB 3.4 MB/s eta 0:00:36\n",
      "   ------------------------- -------------- 211.6/331.9 MB 3.4 MB/s eta 0:00:36\n",
      "   ------------------------- -------------- 212.1/331.9 MB 3.4 MB/s eta 0:00:36\n",
      "   ------------------------- -------------- 212.3/331.9 MB 3.3 MB/s eta 0:00:36\n",
      "   ------------------------- -------------- 212.6/331.9 MB 3.3 MB/s eta 0:00:36\n",
      "   ------------------------- -------------- 212.9/331.9 MB 3.3 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 213.1/331.9 MB 3.3 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 213.4/331.9 MB 3.2 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 213.6/331.9 MB 3.2 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 213.9/331.9 MB 3.2 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 214.2/331.9 MB 3.2 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 214.7/331.9 MB 3.1 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 215.0/331.9 MB 3.1 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 215.2/331.9 MB 3.1 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 215.5/331.9 MB 3.0 MB/s eta 0:00:39\n",
      "   -------------------------- ------------- 215.7/331.9 MB 3.0 MB/s eta 0:00:39\n",
      "   -------------------------- ------------- 216.3/331.9 MB 3.0 MB/s eta 0:00:39\n",
      "   -------------------------- ------------- 216.8/331.9 MB 2.9 MB/s eta 0:00:40\n",
      "   -------------------------- ------------- 217.1/331.9 MB 2.9 MB/s eta 0:00:40\n",
      "   -------------------------- ------------- 217.6/331.9 MB 2.9 MB/s eta 0:00:40\n",
      "   -------------------------- ------------- 218.1/331.9 MB 2.9 MB/s eta 0:00:40\n",
      "   -------------------------- ------------- 218.6/331.9 MB 2.8 MB/s eta 0:00:40\n",
      "   -------------------------- ------------- 219.2/331.9 MB 2.8 MB/s eta 0:00:41\n",
      "   -------------------------- ------------- 219.7/331.9 MB 2.8 MB/s eta 0:00:41\n",
      "   -------------------------- ------------- 220.2/331.9 MB 2.7 MB/s eta 0:00:41\n",
      "   -------------------------- ------------- 221.0/331.9 MB 2.7 MB/s eta 0:00:42\n",
      "   -------------------------- ------------- 221.5/331.9 MB 2.7 MB/s eta 0:00:42\n",
      "   -------------------------- ------------- 222.0/331.9 MB 2.6 MB/s eta 0:00:42\n",
      "   -------------------------- ------------- 222.8/331.9 MB 2.6 MB/s eta 0:00:43\n",
      "   -------------------------- ------------- 223.3/331.9 MB 2.6 MB/s eta 0:00:43\n",
      "   --------------------------- ------------ 224.1/331.9 MB 2.5 MB/s eta 0:00:43\n",
      "   --------------------------- ------------ 224.9/331.9 MB 2.5 MB/s eta 0:00:43\n",
      "   --------------------------- ------------ 225.7/331.9 MB 2.5 MB/s eta 0:00:42\n",
      "   --------------------------- ------------ 226.2/331.9 MB 2.5 MB/s eta 0:00:42\n",
      "   --------------------------- ------------ 227.0/331.9 MB 2.5 MB/s eta 0:00:42\n",
      "   --------------------------- ------------ 227.8/331.9 MB 2.5 MB/s eta 0:00:42\n",
      "   --------------------------- ------------ 228.6/331.9 MB 2.5 MB/s eta 0:00:41\n",
      "   --------------------------- ------------ 229.6/331.9 MB 2.5 MB/s eta 0:00:41\n",
      "   --------------------------- ------------ 230.4/331.9 MB 2.5 MB/s eta 0:00:41\n",
      "   --------------------------- ------------ 231.2/331.9 MB 2.5 MB/s eta 0:00:40\n",
      "   --------------------------- ------------ 232.0/331.9 MB 2.5 MB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 233.0/331.9 MB 2.5 MB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 233.8/331.9 MB 2.5 MB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 234.9/331.9 MB 2.5 MB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 235.7/331.9 MB 2.5 MB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 236.7/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 237.8/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 238.8/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 240.1/331.9 MB 2.5 MB/s eta 0:00:37\n",
      "   ----------------------------- ---------- 241.2/331.9 MB 2.5 MB/s eta 0:00:37\n",
      "   ----------------------------- ---------- 242.7/331.9 MB 2.5 MB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 244.1/331.9 MB 2.5 MB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 245.6/331.9 MB 2.6 MB/s eta 0:00:34\n",
      "   ----------------------------- ---------- 247.5/331.9 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------ --------- 249.0/331.9 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------ --------- 250.1/331.9 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------------------ --------- 251.4/331.9 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------------------ --------- 253.0/331.9 MB 2.6 MB/s eta 0:00:31\n",
      "   ------------------------------ --------- 253.8/331.9 MB 2.6 MB/s eta 0:00:31\n",
      "   ------------------------------ --------- 254.8/331.9 MB 2.6 MB/s eta 0:00:30\n",
      "   ------------------------------ --------- 256.1/331.9 MB 2.6 MB/s eta 0:00:29\n",
      "   ------------------------------ --------- 257.2/331.9 MB 2.6 MB/s eta 0:00:29\n",
      "   ------------------------------- -------- 258.2/331.9 MB 2.7 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 259.3/331.9 MB 2.7 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 260.6/331.9 MB 2.7 MB/s eta 0:00:27\n",
      "   ------------------------------- -------- 261.4/331.9 MB 2.7 MB/s eta 0:00:27\n",
      "   ------------------------------- -------- 262.1/331.9 MB 2.7 MB/s eta 0:00:26\n",
      "   ------------------------------- -------- 263.2/331.9 MB 2.7 MB/s eta 0:00:26\n",
      "   ------------------------------- -------- 264.0/331.9 MB 2.7 MB/s eta 0:00:25\n",
      "   ------------------------------- -------- 264.8/331.9 MB 2.7 MB/s eta 0:00:25\n",
      "   -------------------------------- ------- 265.8/331.9 MB 2.7 MB/s eta 0:00:25\n",
      "   -------------------------------- ------- 266.9/331.9 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 267.6/331.9 MB 2.8 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 268.7/331.9 MB 2.8 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 269.5/331.9 MB 2.8 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 270.5/331.9 MB 2.8 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 271.6/331.9 MB 2.8 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 272.6/331.9 MB 2.8 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 273.7/331.9 MB 2.8 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 274.7/331.9 MB 2.8 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 275.8/331.9 MB 2.8 MB/s eta 0:00:20\n",
      "   --------------------------------- ------ 276.8/331.9 MB 2.9 MB/s eta 0:00:20\n",
      "   --------------------------------- ------ 278.1/331.9 MB 2.9 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 279.2/331.9 MB 2.9 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 280.2/331.9 MB 2.9 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 281.3/331.9 MB 3.0 MB/s eta 0:00:18\n",
      "   ---------------------------------- ----- 282.3/331.9 MB 3.0 MB/s eta 0:00:17\n",
      "   ---------------------------------- ----- 283.1/331.9 MB 3.0 MB/s eta 0:00:17\n",
      "   ---------------------------------- ----- 283.9/331.9 MB 3.0 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 285.0/331.9 MB 3.0 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 286.0/331.9 MB 3.0 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 287.0/331.9 MB 3.1 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 288.1/331.9 MB 3.1 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 289.1/331.9 MB 3.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 289.9/331.9 MB 3.1 MB/s eta 0:00:14\n",
      "   ----------------------------------- ---- 291.0/331.9 MB 3.1 MB/s eta 0:00:14\n",
      "   ----------------------------------- ---- 291.8/331.9 MB 3.1 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 292.6/331.9 MB 3.2 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 293.3/331.9 MB 3.2 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 294.4/331.9 MB 3.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 295.2/331.9 MB 3.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 296.0/331.9 MB 3.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 296.7/331.9 MB 3.2 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 297.8/331.9 MB 3.2 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 298.6/331.9 MB 3.2 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 299.6/331.9 MB 3.3 MB/s eta 0:00:10\n",
      "   ------------------------------------ --- 300.7/331.9 MB 3.3 MB/s eta 0:00:10\n",
      "   ------------------------------------ --- 301.5/331.9 MB 3.3 MB/s eta 0:00:10\n",
      "   ------------------------------------ --- 302.5/331.9 MB 3.3 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 303.6/331.9 MB 3.3 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 304.6/331.9 MB 3.4 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 305.7/331.9 MB 3.4 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 306.7/331.9 MB 3.4 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 308.0/331.9 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 309.1/331.9 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 310.1/331.9 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 311.4/331.9 MB 3.6 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 312.5/331.9 MB 3.6 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 313.5/331.9 MB 3.6 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 314.6/331.9 MB 3.6 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 315.4/331.9 MB 3.7 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 316.4/331.9 MB 3.7 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 317.5/331.9 MB 3.7 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 318.5/331.9 MB 3.7 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 319.6/331.9 MB 3.8 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 320.6/331.9 MB 3.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 321.7/331.9 MB 3.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 322.7/331.9 MB 3.8 MB/s eta 0:00:03\n",
      "   ---------------------------------------  324.0/331.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------------------------------------  325.1/331.9 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  326.1/331.9 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  327.4/331.9 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  328.5/331.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  329.8/331.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  330.8/331.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 331.9/331.9 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.75.1-cp312-cp312-win_amd64.whl (4.6 MB)\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.0/4.6 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.4/4.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.4/4.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.6/4.6 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.0/1.4 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/26.4 MB 5.6 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.4/26.4 MB 5.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 5.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 5.0/26.4 MB 6.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.3/26.4 MB 6.0 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.6/26.4 MB 6.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 9.2/26.4 MB 6.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 10.5/26.4 MB 6.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 11.8/26.4 MB 6.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 13.4/26.4 MB 6.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 14.7/26.4 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 16.3/26.4 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.6/26.4 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 19.1/26.4 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 20.7/26.4 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.3/26.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.9/26.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.9/26.4 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.7/26.4 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 6.2 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl (208 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/5.5 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.5 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.2/5.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-win_amd64.whl (314 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, typing_extensions, termcolor, tensorboard-data-server, protobuf, opt_einsum, ml_dtypes, google_pasta, gast, astunparse, absl-py, optree, grpcio, tensorboard, keras, tensorflow\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.75.1 keras-3.11.3 libclang-18.1.1 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 protobuf-6.33.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 typing_extensions-4.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from recsys_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Notation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|General <br />  Notation  | Description| Python (if any) |\n",
    "|:-------------|:------------------------------------------------------------||\n",
    "| $r(i,j)$     | scalar; = 1  if user j rated movie i  = 0  otherwise             ||\n",
    "| $y(i,j)$     | scalar; = rating given by user j on movie  i    (if r(i,j) = 1 is defined) ||\n",
    "|$\\mathbf{w}^{(j)}$ | vector; parameters for user j ||\n",
    "|$b^{(j)}$     |  scalar; parameter for user j ||\n",
    "| $\\mathbf{x}^{(i)}$ |   vector; feature ratings for movie i        ||     \n",
    "| $n_u$        | number of users |num_users|\n",
    "| $n_m$        | number of movies | num_movies |\n",
    "| $n$          | number of features | num_features                    |\n",
    "| $\\mathbf{X}$ |  matrix of vectors $\\mathbf{x}^{(i)}$         | X |\n",
    "| $\\mathbf{W}$ |  matrix of vectors $\\mathbf{w}^{(j)}$         | W |\n",
    "| $\\mathbf{b}$ |  vector of bias parameters $b^{(j)}$ | b |\n",
    "| $\\mathbf{R}$ | matrix of elements $r(i,j)$                    | R |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Recommender Systems <img align=\"left\" src=\"./images/film_rating.png\" style=\" width:40px;  \" >\n",
    "In this lab, you will implement the collaborative filtering learning algorithm and apply it to a dataset of movie ratings.\n",
    "The goal of a collaborative filtering recommender system is to generate two vectors: For each user, a 'parameter vector' that embodies the movie tastes of a user. For each movie, a feature vector of the same size which embodies some description of the movie. The dot product of the two vectors plus the bias term should produce an estimate of the rating the user might give to that movie.\n",
    "\n",
    "The diagram below details how these vectors are learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "   <img src=\"./images/ColabFilterLearn.PNG\"  style=\"width:740px;height:250px;\" >\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existing ratings are provided in matrix form as shown. $Y$ contains ratings; 0.5 to 5 inclusive in 0.5 steps. 0 if the movie has not been rated. $R$ has a 1 where movies have been rated. Movies are in rows, users in columns. Each user has a parameter vector $w^{user}$ and bias. Each movie has a feature vector $x^{movie}$. These vectors are simultaneously learned by using the existing user/movie ratings as training data. One training example is shown above: $\\mathbf{w}^{(1)} \\cdot \\mathbf{x}^{(1)} + b^{(1)} = 4$. It is worth noting that the feature vector $x^{movie}$ must satisfy all the users while the user vector $w^{user}$ must satisfy all the movies. This is the source of the name of this approach - all the users collaborate to generate the rating set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "   <img src=\"./images/ColabFilterUse.PNG\"  style=\"width:640px;height:250px;\" >\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the feature vectors and parameters are learned, they can be used to predict how a user might rate an unrated movie. This is shown in the diagram above. The equation is an example of predicting a rating for user one on movie zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this exercise, you will implement the function `cofiCostFunc` that computes the collaborative filtering\n",
    "objective function. After implementing the objective function, you will use a TensorFlow custom training loop to learn the parameters for collaborative filtering. The first step is to detail the data set and data structures that will be used in the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-09Hto6odYD"
   },
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - Movie ratings dataset <img align=\"left\" src=\"./images/film_rating.png\"     style=\" width:40px;  \" >\n",
    "The data set is derived from the [MovieLens \"ml-latest-small\"](https://grouplens.org/datasets/movielens/latest/) dataset.   \n",
    "[F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:119:19. <https://doi.org/10.1145/2827872>]\n",
    "\n",
    "The original dataset has  9000 movies rated by 600 users. The dataset has been reduced in size to focus on movies from the years since 2000. This dataset consists of ratings on a scale of 0.5 to 5 in 0.5 step increments. The reduced dataset has $n_u = 443$ users, and $n_m= 4778$ movies. \n",
    "\n",
    "Below, you will load the movie dataset into the variables $Y$ and $R$.\n",
    "\n",
    "The matrix $Y$ (a  $n_m \\times n_u$ matrix) stores the ratings $y^{(i,j)}$. The matrix $R$ is an binary-valued indicator matrix, where $R(i,j) = 1$ if user $j$ gave a rating to movie $i$, and $R(i,j)=0$ otherwise. \n",
    "\n",
    "Throughout this part of the exercise, you will also be working with the\n",
    "matrices, $\\mathbf{X}$, $\\mathbf{W}$ and $\\mathbf{b}$: \n",
    "\n",
    "$$\\mathbf{X} = \n",
    "\\begin{bmatrix}\n",
    "--- (\\mathbf{x}^{(0)})^T --- \\\\\n",
    "--- (\\mathbf{x}^{(1)})^T --- \\\\\n",
    "\\vdots \\\\\n",
    "--- (\\mathbf{x}^{(n_m-1)})^T --- \\\\\n",
    "\\end{bmatrix} , \\quad\n",
    "\\mathbf{W} = \n",
    "\\begin{bmatrix}\n",
    "--- (\\mathbf{w}^{(0)})^T --- \\\\\n",
    "--- (\\mathbf{w}^{(1)})^T --- \\\\\n",
    "\\vdots \\\\\n",
    "--- (\\mathbf{w}^{(n_u-1)})^T --- \\\\\n",
    "\\end{bmatrix},\\quad\n",
    "\\mathbf{ b} = \n",
    "\\begin{bmatrix}\n",
    " b^{(0)}  \\\\\n",
    " b^{(1)} \\\\\n",
    "\\vdots \\\\\n",
    "b^{(n_u-1)} \\\\\n",
    "\\end{bmatrix}\\quad\n",
    "$$ \n",
    "\n",
    "The $i$-th row of $\\mathbf{X}$ corresponds to the\n",
    "feature vector $x^{(i)}$ for the $i$-th movie, and the $j$-th row of\n",
    "$\\mathbf{W}$ corresponds to one parameter vector $\\mathbf{w}^{(j)}$, for the\n",
    "$j$-th user. Both $x^{(i)}$ and $\\mathbf{w}^{(j)}$ are $n$-dimensional\n",
    "vectors. For the purposes of this exercise, you will use $n=10$, and\n",
    "therefore, $\\mathbf{x}^{(i)}$ and $\\mathbf{w}^{(j)}$ have 10 elements.\n",
    "Correspondingly, $\\mathbf{X}$ is a\n",
    "$n_m \\times 10$ matrix and $\\mathbf{W}$ is a $n_u \\times 10$ matrix.\n",
    "\n",
    "We will start by loading the movie ratings dataset to understand the structure of the data.\n",
    "We will load $Y$ and $R$ with the movie dataset.  \n",
    "We'll also load $\\mathbf{X}$, $\\mathbf{W}$, and $\\mathbf{b}$ with pre-computed values. These values will be learned later in the lab, but we'll use pre-computed values to develop the cost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (4778, 443) R (4778, 443)\n",
      "X (4778, 10)\n",
      "W (443, 10)\n",
      "b (1, 443)\n",
      "num_features 10\n",
      "num_movies 4778\n",
      "num_users 443\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "X, W, b, num_movies, num_features, num_users = load_precalc_params_small()\n",
    "Y, R = load_ratings_small()\n",
    "\n",
    "print(\"Y\", Y.shape, \"R\", R.shape)\n",
    "print(\"X\", X.shape)\n",
    "print(\"W\", W.shape)\n",
    "print(\"b\", b.shape)\n",
    "print(\"num_features\", num_features)\n",
    "print(\"num_movies\",   num_movies)\n",
    "print(\"num_users\",    num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bxm1O_wbodYF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating for movie 1 : 3.400 / 5\n"
     ]
    }
   ],
   "source": [
    "#  From the matrix, we can compute statistics like average rating.\n",
    "tsmean =  np.mean(Y[0, R[0, :].astype(bool)])\n",
    "print(f\"Average rating for movie 1 : {tsmean:0.3f} / 5\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4 - Collaborative filtering learning algorithm <img align=\"left\" src=\"./images/film_filter.png\"     style=\" width:40px;  \" >\n",
    "\n",
    "Now, you will begin implementing the collaborative filtering learning\n",
    "algorithm. You will start by implementing the objective function. \n",
    "\n",
    "The collaborative filtering algorithm in the setting of movie\n",
    "recommendations considers a set of $n$-dimensional parameter vectors\n",
    "$\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)}$, $\\mathbf{w}^{(0)},...,\\mathbf{w}^{(n_u-1)}$ and $b^{(0)},...,b^{(n_u-1)}$, where the\n",
    "model predicts the rating for movie $i$ by user $j$ as\n",
    "$y^{(i,j)} = \\mathbf{w}^{(j)}\\cdot \\mathbf{x}^{(i)} + b^{(j)}$ . Given a dataset that consists of\n",
    "a set of ratings produced by some users on some movies, you wish to\n",
    "learn the parameter vectors $\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)},\n",
    "\\mathbf{w}^{(0)},...,\\mathbf{w}^{(n_u-1)}$  and $b^{(0)},...,b^{(n_u-1)}$ that produce the best fit (minimizes\n",
    "the squared error).\n",
    "\n",
    "You will complete the code in cofiCostFunc to compute the cost\n",
    "function for collaborative filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcqg0LJWodYH"
   },
   "source": [
    "\n",
    "<a name=\"4.1\"></a>\n",
    "### 4.1 Collaborative filtering cost function\n",
    "\n",
    "The collaborative filtering cost function is given by\n",
    "$$J({\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)},\\mathbf{w}^{(0)},b^{(0)},...,\\mathbf{w}^{(n_u-1)},b^{(n_u-1)}})= \\left[ \\frac{1}{2}\\sum_{(i,j):r(i,j)=1}(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+ \\underbrace{\\left[\n",
    "\\frac{\\lambda}{2}\n",
    "\\sum_{j=0}^{n_u-1}\\sum_{k=0}^{n-1}(\\mathbf{w}^{(j)}_k)^2\n",
    "+ \\frac{\\lambda}{2}\\sum_{i=0}^{n_m-1}\\sum_{k=0}^{n-1}(\\mathbf{x}_k^{(i)})^2\n",
    "\\right]}_{regularization}\n",
    "\\tag{1}$$\n",
    "The first summation in (1) is \"for all $i$, $j$ where $r(i,j)$ equals $1$\" and could be written:\n",
    "\n",
    "$$\n",
    "= \\left[ \\frac{1}{2}\\sum_{j=0}^{n_u-1} \\sum_{i=0}^{n_m-1}r(i,j)*(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+\\text{regularization}\n",
    "$$\n",
    "\n",
    "You should now write cofiCostFunc (collaborative filtering cost function) to return this cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex01\"></a>\n",
    "### Exercise 1\n",
    "\n",
    "**For loop Implementation:**   \n",
    "Start by implementing the cost function using for loops.\n",
    "Consider developing the cost function in two steps. First, develop the cost function without regularization. A test case that does not include regularization is provided below to test your implementation. Once that is working, add regularization and run the tests that include regularization.  Note that you should be accumulating the cost for user $j$ and movie $i$ only if $R(i,j) = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: cofi_cost_func\n",
    "# UNQ_C1\n",
    "\n",
    "def cofi_cost_func(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    nm, nu = Y.shape\n",
    "    J = 0\n",
    "    \n",
    "    for i in range(nm):\n",
    "        for j in range(nu):\n",
    "            if R[i, j] == 1:\n",
    "                y_hat = np.dot(X[i, :], W[j, :]) + b[0, j]\n",
    "                err = y_hat - Y[i, j]\n",
    "                J += 0.5 * (err ** 2)\n",
    "\n",
    "    J += (lambda_ / 2.0) * (np.sum(X ** 2) + np.sum(W ** 2))\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click for hints</b></font></summary>\n",
    "    You can structure the code in two for loops similar to the summation in (1).   \n",
    "    Implement the code without regularization first.   \n",
    "    Note that some of the elements in (1) are vectors. Use np.dot(). You can also use np.square().\n",
    "    Pay close attention to which elements are indexed by i and which are indexed by j. Don't forget to divide by two.\n",
    "    \n",
    "```python     \n",
    "    ### START CODE HERE ###  \n",
    "    for j in range(nu):\n",
    "        \n",
    "        \n",
    "        for i in range(nm):\n",
    "            \n",
    "            \n",
    "    ### END CODE HERE ### \n",
    "```    \n",
    "<details>\n",
    "    <summary><font size=\"2\" color=\"darkblue\"><b> Click for more hints</b></font></summary>\n",
    "        \n",
    "    Here is some more details. The code below pulls out each element from the matrix before using it. \n",
    "    One could also reference the matrix directly.  \n",
    "    This code does not contain regularization.\n",
    "    \n",
    "```python \n",
    "    nm,nu = Y.shape\n",
    "    J = 0\n",
    "    ### START CODE HERE ###  \n",
    "    for j in range(nu):\n",
    "        w = W[j,:]\n",
    "        b_j = b[0,j]\n",
    "        for i in range(nm):\n",
    "            x = \n",
    "            y = \n",
    "            r =\n",
    "            J += \n",
    "    J = J/2\n",
    "    ### END CODE HERE ### \n",
    "\n",
    "```\n",
    "    \n",
    "<details>\n",
    "    <summary><font size=\"2\" color=\"darkblue\"><b>Last Resort (full non-regularized implementation)</b></font></summary>\n",
    "    \n",
    "```python \n",
    "    nm,nu = Y.shape\n",
    "    J = 0\n",
    "    ### START CODE HERE ###  \n",
    "    for j in range(nu):\n",
    "        w = W[j,:]\n",
    "        b_j = b[0,j]\n",
    "        for i in range(nm):\n",
    "            x = X[i,:]\n",
    "            y = Y[i,j]\n",
    "            r = R[i,j]\n",
    "            J += np.square(r * (np.dot(w,x) + b_j - y ) )\n",
    "    J = J/2\n",
    "    ### END CODE HERE ### \n",
    "```\n",
    "    \n",
    "<details>\n",
    "    <summary><font size=\"2\" color=\"darkblue\"><b>regularization</b></font></summary>\n",
    "     Regularization just squares each element of the W array and X array and them sums all the squared elements.\n",
    "     You can utilize np.square() and np.sum().\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"2\" color=\"darkblue\"><b>regularization details</b></font></summary>\n",
    "    \n",
    "```python \n",
    "    J += (lambda_/2) * (np.sum(np.square(W)) + np.sum(np.square(X)))\n",
    "```\n",
    "    \n",
    "</details>\n",
    "</details>\n",
    "</details>\n",
    "</details>\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 13.67\n"
     ]
    }
   ],
   "source": [
    "# Reduce the data set size so that this runs faster\n",
    "num_users_r = 4\n",
    "num_movies_r = 5 \n",
    "num_features_r = 3\n",
    "\n",
    "X_r = X[:num_movies_r, :num_features_r]\n",
    "W_r = W[:num_users_r,  :num_features_r]\n",
    "b_r = b[0, :num_users_r].reshape(1,-1)\n",
    "Y_r = Y[:num_movies_r, :num_users_r]\n",
    "R_r = R[:num_movies_r, :num_users_r]\n",
    "\n",
    "# Evaluate cost function\n",
    "J = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 0);\n",
    "print(f\"Cost: {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGznmQ91odYL"
   },
   "source": [
    "**Expected Output (lambda = 0)**:  \n",
    "$13.67$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (with regularization): 28.09\n"
     ]
    }
   ],
   "source": [
    "# Evaluate cost function with regularization \n",
    "J = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 1.5);\n",
    "print(f\"Cost (with regularization): {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xbepzUUodYP"
   },
   "source": [
    "**Expected Output**:\n",
    "\n",
    "28.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Public tests\n",
    "from public_tests import *\n",
    "test_cofi_cost_func(cofi_cost_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorized Implementation**\n",
    "\n",
    "It is important to create a vectorized implementation to compute $J$, since it will later be called many times during optimization. The linear algebra utilized is not the focus of this series, so the implementation is provided. If you are an expert in linear algebra, feel free to create your version without referencing the code below. \n",
    "\n",
    "Run the code below and verify that it produces the same results as the non-vectorized version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 13.67\n",
      "Cost (with regularization): 28.09\n"
     ]
    }
   ],
   "source": [
    "# Evaluate cost function\n",
    "J = cofi_cost_func_v(X_r, W_r, b_r, Y_r, R_r, 0);\n",
    "print(f\"Cost: {J:0.2f}\")\n",
    "\n",
    "# Evaluate cost function with regularization \n",
    "J = cofi_cost_func_v(X_r, W_r, b_r, Y_r, R_r, 1.5);\n",
    "print(f\"Cost (with regularization): {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xbepzUUodYP"
   },
   "source": [
    "**Expected Output**:  \n",
    "Cost: 13.67  \n",
    "Cost (with regularization): 28.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilaeM8yWodYR"
   },
   "source": [
    "<a name=\"5\"></a>\n",
    "## 5 - Learning movie recommendations <img align=\"left\" src=\"./images/film_man_action.png\" style=\" width:40px;  \" >\n",
    "------------------------------\n",
    "\n",
    "After you have finished implementing the collaborative filtering cost\n",
    "function, you can start training your algorithm to make\n",
    "movie recommendations for yourself. \n",
    "\n",
    "In the cell below, you can enter your own movie choices. The algorithm will then make recommendations for you! We have filled out some values according to our preferences, but after you have things working with our choices, you should change this to match your tastes.\n",
    "A list of all movies in the dataset is in the file [movie list](data/small_movie_list.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "id": "WJO8Jr0UodYR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New user ratings:\n",
      "\n",
      "Rated 5.0 for  Shrek (2001)\n",
      "Rated 5.0 for  Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Rated 2.0 for  Amelie (Fabuleux destin d'Amlie Poulain, Le) (2001)\n",
      "Rated 5.0 for  Harry Potter and the Chamber of Secrets (2002)\n",
      "Rated 5.0 for  Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Rated 5.0 for  Lord of the Rings: The Return of the King, The (2003)\n",
      "Rated 3.0 for  Eternal Sunshine of the Spotless Mind (2004)\n",
      "Rated 5.0 for  Incredibles, The (2004)\n",
      "Rated 2.0 for  Persuasion (2007)\n",
      "Rated 5.0 for  Toy Story 3 (2010)\n",
      "Rated 3.0 for  Inception (2010)\n",
      "Rated 1.0 for  Louis Theroux: Law & Disorder (2008)\n",
      "Rated 1.0 for  Nothing to Declare (Rien  dclarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "movieList, movieList_df = load_Movie_List_pd()\n",
    "\n",
    "my_ratings = np.zeros(num_movies)          #  Initialize my ratings\n",
    "\n",
    "# Check the file small_movie_list.csv for id of each movie in our dataset\n",
    "# For example, Toy Story 3 (2010) has ID 2700, so to rate it \"5\", you can set\n",
    "my_ratings[2700] = 5 \n",
    "\n",
    "#Or suppose you did not enjoy Persuasion (2007), you can set\n",
    "my_ratings[2609] = 2;\n",
    "\n",
    "# We have selected a few movies we liked / did not like and the ratings we\n",
    "# gave are as follows:\n",
    "my_ratings[929]  = 5   # Lord of the Rings: The Return of the King, The\n",
    "my_ratings[246]  = 5   # Shrek (2001)\n",
    "my_ratings[2716] = 3   # Inception\n",
    "my_ratings[1150] = 5   # Incredibles, The (2004)\n",
    "my_ratings[382]  = 2   # Amelie (Fabuleux destin d'Amlie Poulain, Le)\n",
    "my_ratings[366]  = 5   # Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
    "my_ratings[622]  = 5   # Harry Potter and the Chamber of Secrets (2002)\n",
    "my_ratings[988]  = 3   # Eternal Sunshine of the Spotless Mind (2004)\n",
    "my_ratings[2925] = 1   # Louis Theroux: Law & Disorder (2008)\n",
    "my_ratings[2937] = 1   # Nothing to Declare (Rien  dclarer)\n",
    "my_ratings[793]  = 5   # Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
    "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "\n",
    "print('\\nNew user ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0 :\n",
    "        print(f'Rated {my_ratings[i]} for  {movieList_df.loc[i,\"title\"]}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add these reviews to $Y$ and $R$ and normalize the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Reload ratings\n",
    "Y, R = load_ratings_small()\n",
    "\n",
    "# Add new user ratings to Y \n",
    "Y = np.c_[my_ratings, Y]\n",
    "\n",
    "# Add new user indicator matrix to R\n",
    "R = np.c_[(my_ratings != 0).astype(int), R]\n",
    "\n",
    "# Normalize the Dataset\n",
    "Ynorm, Ymean = normalizeRatings(Y, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare to train the model. Initialize the parameters and select the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Useful Values\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 100\n",
    "\n",
    "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train the collaborative filtering model. This will learn the parameters $\\mathbf{X}$, $\\mathbf{W}$, and $\\mathbf{b}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operations involved in learning $w$, $b$, and $x$ simultaneously do not fall into the typical 'layers' offered in the TensorFlow neural network package.  Consequently, the flow used in Course 2: Model, Compile(), Fit(), Predict(), are not directly applicable. Instead, we can use a custom training loop.\n",
    "\n",
    "Recall from earlier labs the steps of gradient descent.\n",
    "- repeat until convergence:\n",
    "    - compute forward pass\n",
    "    - compute the derivatives of the loss relative to parameters\n",
    "    - update the parameters using the learning rate and the computed derivatives \n",
    "    \n",
    "TensorFlow has the marvelous capability of calculating the derivatives for you. This is shown below. Within the `tf.GradientTape()` section, operations on Tensorflow Variables are tracked. When `tape.gradient()` is later called, it will return the gradient of the loss relative to the tracked variables. The gradients can then be applied to the parameters using an optimizer. \n",
    "This is a very brief introduction to a useful feature of TensorFlow and other machine learning frameworks. Further information can be found by investigating \"custom training loops\" within the framework of interest.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 2321191.3\n",
      "Training loss at iteration 20: 136169.3\n",
      "Training loss at iteration 40: 51863.7\n",
      "Training loss at iteration 60: 24599.0\n",
      "Training loss at iteration 80: 13630.6\n",
      "Training loss at iteration 100: 8487.7\n",
      "Training loss at iteration 120: 5807.8\n",
      "Training loss at iteration 140: 4311.6\n",
      "Training loss at iteration 160: 3435.3\n",
      "Training loss at iteration 180: 2902.1\n"
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "lambda_ = 1\n",
    "for iter in range(iterations):\n",
    "    # Use TensorFlows GradientTape\n",
    "    # to record the operations used to compute the cost \n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Compute the cost (forward pass included in cost)\n",
    "        cost_value = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n",
    "\n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss\n",
    "    grads = tape.gradient( cost_value, [X,W,b] )\n",
    "\n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of the variables to minimize the loss.\n",
    "    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n",
    "\n",
    "    # Log periodically.\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSzUL7eQodYS"
   },
   "source": [
    "<a name=\"6\"></a>\n",
    "## 6 - Recommendations\n",
    "Below, we compute the ratings for all the movies and users and display the movies that are recommended. These are based on the movies and ratings entered as `my_ratings[]` above. To predict the rating of movie $i$ for user $j$, you compute $\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)}$. This can be computed for all ratings using matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ns266wKtodYT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting rating 4.49 for movie My Sassy Girl (Yeopgijeogin geunyeo) (2001)\n",
      "Predicting rating 4.48 for movie Martin Lawrence Live: Runteldat (2002)\n",
      "Predicting rating 4.48 for movie Memento (2000)\n",
      "Predicting rating 4.47 for movie Delirium (2014)\n",
      "Predicting rating 4.47 for movie Laggies (2014)\n",
      "Predicting rating 4.47 for movie One I Love, The (2014)\n",
      "Predicting rating 4.46 for movie Particle Fever (2013)\n",
      "Predicting rating 4.45 for movie Eichmann (2007)\n",
      "Predicting rating 4.45 for movie Battle Royale 2: Requiem (Batoru rowaiaru II: Chinkonka) (2003)\n",
      "Predicting rating 4.45 for movie Into the Abyss (2011)\n",
      "\n",
      "\n",
      "Original vs Predicted ratings:\n",
      "\n",
      "Original 5.0, Predicted 4.90 for Shrek (2001)\n",
      "Original 5.0, Predicted 4.84 for Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Original 2.0, Predicted 2.13 for Amelie (Fabuleux destin d'Amlie Poulain, Le) (2001)\n",
      "Original 5.0, Predicted 4.88 for Harry Potter and the Chamber of Secrets (2002)\n",
      "Original 5.0, Predicted 4.87 for Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Original 5.0, Predicted 4.89 for Lord of the Rings: The Return of the King, The (2003)\n",
      "Original 3.0, Predicted 3.00 for Eternal Sunshine of the Spotless Mind (2004)\n",
      "Original 5.0, Predicted 4.90 for Incredibles, The (2004)\n",
      "Original 2.0, Predicted 2.11 for Persuasion (2007)\n",
      "Original 5.0, Predicted 4.80 for Toy Story 3 (2010)\n",
      "Original 3.0, Predicted 3.00 for Inception (2010)\n",
      "Original 1.0, Predicted 1.41 for Louis Theroux: Law & Disorder (2008)\n",
      "Original 1.0, Predicted 1.26 for Nothing to Declare (Rien  dclarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using trained weights and biases\n",
    "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "\n",
    "#restore the mean\n",
    "pm = p + Ymean\n",
    "\n",
    "my_predictions = pm[:,0]\n",
    "\n",
    "# sort predictions\n",
    "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "for i in range(17):\n",
    "    j = ix[i]\n",
    "    if j not in my_rated:\n",
    "        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movieList[j]}')\n",
    "\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, additional information can be utilized to enhance our predictions. Above, the predicted ratings for the first few hundred movies lie in a small range. We can augment the above by selecting from those top movies, movies that have high average ratings and movies with more than 20 ratings. This section uses a [Pandas](https://pandas.pydata.org/) data frame which has many handy sorting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>mean rating</th>\n",
       "      <th>number of ratings</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>4.030961</td>\n",
       "      <td>4.252336</td>\n",
       "      <td>107</td>\n",
       "      <td>Departed, The (2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>3.985281</td>\n",
       "      <td>4.238255</td>\n",
       "      <td>149</td>\n",
       "      <td>Dark Knight, The (2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>4.477798</td>\n",
       "      <td>4.122642</td>\n",
       "      <td>159</td>\n",
       "      <td>Memento (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>4.887054</td>\n",
       "      <td>4.118919</td>\n",
       "      <td>185</td>\n",
       "      <td>Lord of the Rings: The Return of the King, The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>4.796531</td>\n",
       "      <td>4.109091</td>\n",
       "      <td>55</td>\n",
       "      <td>Toy Story 3 (2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>4.357304</td>\n",
       "      <td>4.021277</td>\n",
       "      <td>188</td>\n",
       "      <td>Lord of the Rings: The Two Towers, The (2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>4.004471</td>\n",
       "      <td>4.006494</td>\n",
       "      <td>77</td>\n",
       "      <td>Shaun of the Dead (2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>3.980649</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61</td>\n",
       "      <td>Hot Fuzz (2007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>4.084643</td>\n",
       "      <td>3.993421</td>\n",
       "      <td>76</td>\n",
       "      <td>Dark Knight Rises, The (2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>4.434171</td>\n",
       "      <td>3.989362</td>\n",
       "      <td>47</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1 (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>4.289676</td>\n",
       "      <td>3.960993</td>\n",
       "      <td>141</td>\n",
       "      <td>Finding Nemo (2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>4.344999</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>81</td>\n",
       "      <td>Casino Royale (2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>4.133481</td>\n",
       "      <td>3.943396</td>\n",
       "      <td>53</td>\n",
       "      <td>How to Train Your Dragon (2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>4.175743</td>\n",
       "      <td>3.887931</td>\n",
       "      <td>58</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>4.135287</td>\n",
       "      <td>3.871212</td>\n",
       "      <td>132</td>\n",
       "      <td>Monsters, Inc. (2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>3.967900</td>\n",
       "      <td>3.869565</td>\n",
       "      <td>69</td>\n",
       "      <td>Avengers, The (2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>4.897137</td>\n",
       "      <td>3.867647</td>\n",
       "      <td>170</td>\n",
       "      <td>Shrek (2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>3.971892</td>\n",
       "      <td>3.836364</td>\n",
       "      <td>110</td>\n",
       "      <td>Crouching Tiger, Hidden Dragon (Wo hu cang lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>4.898892</td>\n",
       "      <td>3.836000</td>\n",
       "      <td>125</td>\n",
       "      <td>Incredibles, The (2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>4.874936</td>\n",
       "      <td>3.778523</td>\n",
       "      <td>149</td>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>4.843375</td>\n",
       "      <td>3.761682</td>\n",
       "      <td>107</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (a.k.a. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>4.021778</td>\n",
       "      <td>3.723684</td>\n",
       "      <td>76</td>\n",
       "      <td>X2: X-Men United (2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4.242986</td>\n",
       "      <td>3.699248</td>\n",
       "      <td>133</td>\n",
       "      <td>X-Men (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>4.878342</td>\n",
       "      <td>3.598039</td>\n",
       "      <td>102</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets (2002)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred  mean rating  number of ratings  \\\n",
       "1743  4.030961     4.252336                107   \n",
       "2112  3.985281     4.238255                149   \n",
       "211   4.477798     4.122642                159   \n",
       "929   4.887054     4.118919                185   \n",
       "2700  4.796531     4.109091                 55   \n",
       "653   4.357304     4.021277                188   \n",
       "1122  4.004471     4.006494                 77   \n",
       "1841  3.980649     4.000000                 61   \n",
       "3083  4.084643     3.993421                 76   \n",
       "2804  4.434171     3.989362                 47   \n",
       "773   4.289676     3.960993                141   \n",
       "1771  4.344999     3.944444                 81   \n",
       "2649  4.133481     3.943396                 53   \n",
       "2455  4.175743     3.887931                 58   \n",
       "361   4.135287     3.871212                132   \n",
       "3014  3.967900     3.869565                 69   \n",
       "246   4.897137     3.867647                170   \n",
       "151   3.971892     3.836364                110   \n",
       "1150  4.898892     3.836000                125   \n",
       "793   4.874936     3.778523                149   \n",
       "366   4.843375     3.761682                107   \n",
       "754   4.021778     3.723684                 76   \n",
       "79    4.242986     3.699248                133   \n",
       "622   4.878342     3.598039                102   \n",
       "\n",
       "                                                  title  \n",
       "1743                               Departed, The (2006)  \n",
       "2112                            Dark Knight, The (2008)  \n",
       "211                                      Memento (2000)  \n",
       "929   Lord of the Rings: The Return of the King, The...  \n",
       "2700                                 Toy Story 3 (2010)  \n",
       "653       Lord of the Rings: The Two Towers, The (2002)  \n",
       "1122                           Shaun of the Dead (2004)  \n",
       "1841                                    Hot Fuzz (2007)  \n",
       "3083                      Dark Knight Rises, The (2012)  \n",
       "2804  Harry Potter and the Deathly Hallows: Part 1 (...  \n",
       "773                                 Finding Nemo (2003)  \n",
       "1771                               Casino Royale (2006)  \n",
       "2649                    How to Train Your Dragon (2010)  \n",
       "2455      Harry Potter and the Half-Blood Prince (2009)  \n",
       "361                               Monsters, Inc. (2001)  \n",
       "3014                               Avengers, The (2012)  \n",
       "246                                        Shrek (2001)  \n",
       "151   Crouching Tiger, Hidden Dragon (Wo hu cang lon...  \n",
       "1150                            Incredibles, The (2004)  \n",
       "793   Pirates of the Caribbean: The Curse of the Bla...  \n",
       "366   Harry Potter and the Sorcerer's Stone (a.k.a. ...  \n",
       "754                             X2: X-Men United (2003)  \n",
       "79                                         X-Men (2000)  \n",
       "622      Harry Potter and the Chamber of Secrets (2002)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter=(movieList_df[\"number of ratings\"] > 20)\n",
    "movieList_df[\"pred\"] = my_predictions\n",
    "movieList_df = movieList_df.reindex(columns=[\"pred\", \"mean rating\", \"number of ratings\", \"title\"])\n",
    "movieList_df.loc[ix[:300]].loc[filter].sort_values(\"mean rating\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"7\"></a>\n",
    "## 7 - Congratulations! <img align=\"left\" src=\"./images/film_award.png\"     style=\" width:40px;  \" >\n",
    "You have implemented a useful recommender system!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"2\" color=\"darkgreen\"><b>Please click here if you want to experiment with any of the non-graded code.</b></font></summary>\n",
    "    <p><i><b>Important Note: Please only do this when you've already passed the assignment to avoid problems with the autograder.</b></i>\n",
    "    <ol>\n",
    "        <li> On the notebooks menu, click View > Cell Toolbar > Edit Metadata</li>\n",
    "        <li> Hit the Edit Metadata button next to the code cell which you want to lock/unlock</li>\n",
    "        <li> Set the attribute value for editable to:\n",
    "            <ul>\n",
    "                <li> true if you want to unlock it </li>\n",
    "                <li> false if you want to lock it </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li> On the notebooks menu, click View > Cell Toolbar > None </li>\n",
    "    </ol>\n",
    "    <p> Here's a short demo of how to do the steps above: \n",
    "        <br>\n",
    "        <img src=\"https://lh3.google.com/u/0/d/14Xy_Mb17CZVgzVAgq7NCjMVBvSae3xO1\" align=\"center\" alt=\"unlock_cells.gif\">\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
